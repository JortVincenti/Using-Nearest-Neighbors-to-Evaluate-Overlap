{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9767c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9fc58e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing as pre\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import optuna\n",
    "import numpy as np\n",
    "from scipy.special import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52dff44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Nearest_Neighbours():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(X, y, k=None):\n",
    "        if k == None:\n",
    "            k= round(0.3*(len(X))**(4/5))\n",
    "        mean_dist, min_dist, max_dist = compute_average_distance(X)\n",
    "        #Take 5% of k-neighbours\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, radius=max_dist, algorithm='auto').fit(X)\n",
    "\n",
    "        distances, indices = nbrs.kneighbors(X, n_neighbors=k, return_distance=True)\n",
    "\n",
    "        return distances, indices\n",
    "    \n",
    "    \n",
    "    def predict(X, distances, indices, y, epsilon, Plotting=None):\n",
    "        final_points = []\n",
    "            \n",
    "        plt_coor = []\n",
    "        estimates_lof = []\n",
    "        estimates_lrd = []\n",
    "\n",
    "        #For all points.\n",
    "        for index, arr in enumerate(indices):\n",
    "\n",
    "            a = np.zeros(shape=(len(arr), 2))\n",
    "\n",
    "            for i in range(len(arr)):\n",
    "                a[i] = np.array([y[arr[i]], distances[index][i]]) #Create an array with [Y_class, distance]\n",
    "\n",
    "            a = a[a.T[0, :].argsort()]\n",
    "            a = np.split(a[:,1], np.unique(a[:, 0], return_index=True)[1][1:]) #Split per class \n",
    "\n",
    "            max_distance_per_class = [max(x) for x in a]\n",
    "            length_per_class = [len(x) for x in a]\n",
    "            sum_reach_dist_per_class = [sum(x) for x in a]\n",
    "\n",
    "            amount_classes =  len(np.unique(y, return_counts=True)[1])\n",
    "            if len(sum_reach_dist_per_class) != amount_classes: #If not all classes are present.\n",
    "                continue #Don't take it into account.\n",
    "\n",
    "            \n",
    "            lrd_per_class = []\n",
    "            lof_per_class = []\n",
    "            classes = np.unique(y)\n",
    "            \n",
    "            for ind in range(amount_classes):\n",
    "                if max_distance_per_class[ind] == 0 and sum_reach_dist_per_class[ind] == 0: #If the only point from the class is the point itself.\n",
    "                    adapted_lrd_estimate = 0 #Then the density is 0 for that class.\n",
    "                    simplifiedlof_estimate = 0 #Then the density is 0 for that class.\n",
    "                else:\n",
    "                    point_class = classes[ind]\n",
    "                    class_length = np.count_nonzero(y == point_class)\n",
    "                    \n",
    "                    amount_of_points_estimate = amount_of_points(length_per_class[ind], class_length)\n",
    "                    adapted_lrd_estimate = adapted_lrd(sum_reach_dist_per_class[ind], length_per_class[ind], dim=len(X[0]))\n",
    "                    adapted_lrd_estimate = (adapted_lrd_estimate * amount_of_points_estimate)\n",
    "                    \n",
    "                    simplifiedlof_estimate = simplifiedLOFEstimate(max_distance_per_class[ind], dim=len(X[0]))\n",
    "                    simplifiedlof_estimate = (simplifiedlof_estimate) * amount_of_points_estimate\n",
    "\n",
    "                lrd_per_class.append(adapted_lrd_estimate)\n",
    "                lof_per_class.append(simplifiedlof_estimate)\n",
    "                \n",
    "            final_points.append(arr[0])\n",
    "            estimates_lof.append(min(lof_per_class))\n",
    "            estimates_lrd.append(min(lrd_per_class))       \n",
    "            plt_coor.append([X[arr[0]]]) #scaler.inverse_transform([X[arr[0]]])[0][0])\n",
    "\n",
    "                        \n",
    "        if Plotting:\n",
    "            plt.scatter(plt_coor, estimates_lrd,alpha=0.4)\n",
    "            plt.scatter(Plotting[0], Plotting[1], alpha=0.4, c=\"red\")\n",
    "            plt.xlabel('Coordinates') \n",
    "            plt.ylabel('Custom Density')\n",
    "            plt.title(\"Density Values LRD\")\n",
    "            plt.legend([\"Estimated Density\", \"True Density\"], fontsize=8)\n",
    "            plt.show()\n",
    "\n",
    "            plt.scatter(plt_coor, estimates_lof, alpha=0.4)\n",
    "            plt.scatter(Plotting[0], Plotting[1], alpha=0.4, c=\"red\")\n",
    "            plt.xlabel('Coordinates') \n",
    "            plt.ylabel('Custom Density')\n",
    "            plt.title(\"Density Values LOF\")\n",
    "            plt.legend([\"Estimated Density\", \"True Density\"], fontsize=8)\n",
    "            plt.show()\n",
    "                \n",
    "        #Return the final points in the interval\n",
    "        final_points_lof = np.asarray(final_points)[np.where(np.asarray(estimates_lof)> epsilon)[:]]\n",
    "        final_points_lrd = np.asarray(final_points)[np.where(np.asarray(estimates_lrd)> epsilon)[:]]\n",
    "        \n",
    "        overlap_lof = None\n",
    "        overlap_lrd = None\n",
    "\n",
    "        if len(final_points_lof) != 0:\n",
    "            overlap_lof = X[list(final_points_lof)[:]]\n",
    " \n",
    "        if len(final_points_lrd) != 0:\n",
    "            overlap_lrd = X[list(final_points_lrd)[:]]\n",
    "\n",
    "        return overlap_lof, overlap_lrd\n",
    "\n",
    "    \n",
    "    def fit_predict(X, y, epsilon):\n",
    "        distances, indices = K_Nearest_Neighbours.fit(X, y)\n",
    "        return K_Nearest_Neighbours.predict(X, distances, indices, y, epsilon, Plotting=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62657050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapted_lrd(class_distance, length_per_class, dim):\n",
    "    Vd = np.pi**(dim/2)/gamma((dim/2)+1)\n",
    "    return 1/(class_distance*Vd*2/length_per_class)\n",
    "\n",
    "def simplifiedLOFEstimate(max_distance_per_class, dim):\n",
    "    Vd = np.pi**(dim/2)/gamma((dim/2)+1)\n",
    "    return 1/(max_distance_per_class * Vd)\n",
    "\n",
    "def amount_of_points(amount_point_class, total_points):\n",
    "    return amount_point_class/total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da989aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_density_estimates():\n",
    "    np.random.seed(0)\n",
    "    epsilon = 0\n",
    "    size = 1000\n",
    "    mean1 = 0  \n",
    "    mean2 = 2 \n",
    "    scale1 = 1\n",
    "    scale2 = 1\n",
    "\n",
    "    x1 = np.random.normal(mean1, scale1, size)\n",
    "    x2 = np.random.normal(mean2, scale2, size)\n",
    "    X = np.concatenate([x1, x2]).reshape(-1, 1)\n",
    "    y = np.concatenate([np.ones(len(x1)), -np.ones(len(x2))])\n",
    "    k=100\n",
    "    \n",
    "    \n",
    "    distances, indices = K_Nearest_Neighbours.fit(X, y, k)\n",
    "    \n",
    "    \n",
    "    f1_distribution = stats.norm.pdf(x=X, loc=mean1, scale=scale1)\n",
    "    f2_distribution = stats.norm.pdf(x=X, loc=mean2, scale=scale2)\n",
    "    class_ov = (f1_distribution > epsilon) & (f2_distribution > epsilon)\n",
    "    X_coor = X[class_ov]\n",
    "    overlap_nn = K_Nearest_Neighbours.predict(X, distances, indices, y, epsilon, Plotting=[X_coor, np.minimum(f1_distribution[class_ov], f2_distribution[class_ov])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baa53830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunning_k_plots_subplot_density_estimates():\n",
    "    import scipy\n",
    "\n",
    "    n=1000\n",
    "    np.random.seed(0)\n",
    "    C_0 = 0.01\n",
    "    epsilon = 0\n",
    "    for i in range(200):\n",
    "        \n",
    "        mean1 = 0  # Change those values to have the other plot.\n",
    "        mean2 = 2\n",
    "        scale1 = 1\n",
    "        scale2 = 1\n",
    "\n",
    "        x1 = np.random.normal(mean1, scale1, n)\n",
    "        x2 = np.random.normal(mean2, scale2, n)\n",
    "        X = np.concatenate([x1, x2]).reshape(-1, 1)\n",
    "        y = np.concatenate([np.ones(len(x1)), -np.ones(len(x2))])\n",
    "\n",
    "        k= round(C_0*(len(X)/2)**(4/5))\n",
    "        distances, indices = K_Nearest_Neighbours.fit(X, y, k)\n",
    "        \n",
    "        f1_distribution = stats.norm.pdf(x=X, loc=mean1, scale=scale1)\n",
    "        f2_distribution = stats.norm.pdf(x=X, loc=mean2, scale=scale2)\n",
    "        class_ov = (f1_distribution > epsilon) & (f2_distribution > epsilon)\n",
    "        X_coor = X[class_ov]\n",
    "        K_Nearest_Neighbours.predict(X, distances, indices, y, epsilon, Plotting=[X_coor, np.minimum(f1_distribution[class_ov], f2_distribution[class_ov])])\n",
    "        C_0 = C_0 + 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "284f8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunning_k_plots(X, y, epsilon, n, C_0, mean1, scale1, mean2, scale2):\n",
    "    \n",
    "    k= round(C_0*(len(X)/2)**(4/5))\n",
    "    distances, indices = K_Nearest_Neighbours.fit(X, y, k)\n",
    "\n",
    "    f1_distribution = stats.uniform.pdf(x=X, loc=mean1, scale=scale1-mean1)\n",
    "    f2_distribution = stats.uniform.pdf(x=X, loc=mean2, scale=scale2-mean2)\n",
    "    class_ov = (f1_distribution > epsilon) & (f2_distribution > epsilon)\n",
    "    overlap = X[class_ov]\n",
    "\n",
    "    overlap_lof, overlap_lrd = K_Nearest_Neighbours.predict(X, distances, indices, y, epsilon)\n",
    "\n",
    "    true_interval = (0,0)\n",
    "    if len(overlap) == 0: #If no true overlap\n",
    "        true_interval == (0, 0)\n",
    "    else: #If overlap\n",
    "        true_interval = (overlap.min(), overlap.max())\n",
    "\n",
    "    y_true = []\n",
    "    for data in X:\n",
    "        if len(overlap) == 0:\n",
    "            y_true.append(0)\n",
    "        elif data > overlap.min() and data < overlap.max():\n",
    "            y_true.append(1)\n",
    "        else:\n",
    "            y_true.append(0)\n",
    "\n",
    "\n",
    "    if overlap_lof is None: #If no estimated overlap\n",
    "        estimated_interval_lof = (0, 0)\n",
    "    else: #If estimated overlap\n",
    "        estimated_interval_lof = (overlap_lof.min(), overlap_lof.max())\n",
    "        overlap_lof = [0]\n",
    "    if overlap_lrd is None: #If no estimated overlap\n",
    "        estimated_interval_lrd = (0, 0)\n",
    "        overlap_lrd = [0]\n",
    "    else: #If estimated overlap\n",
    "        estimated_interval_lrd = (overlap_lrd.min(), overlap_lrd.max())\n",
    "        \n",
    "    IOU_area_lof = IOU(estimated_interval_lof, true_interval)\n",
    "    IOU_point_lof = iou_acc_multiple_dim(X, overlap_lof, y_true)[0]\n",
    "    IOU_area_lrd = IOU(estimated_interval_lrd, true_interval)\n",
    "    IOU_point_lrd = iou_acc_multiple_dim(X, overlap_lrd, y_true)[0]\n",
    "    \n",
    "    return (IOU_area_lof + IOU_point_lof + IOU_area_lrd + IOU_point_lrd)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92d19b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contour_plot():\n",
    "    def objective(trial):    \n",
    "        n = trial.suggest_int(\"nvalues\", 50, 2000)\n",
    "        C_0 = trial.suggest_float(\"C_0 values\", 0.01, 2)\n",
    "        np.random.seed(0)\n",
    "        mean1 = 0  \n",
    "        mean2 = 1 \n",
    "        scale1 = 3\n",
    "        scale2 = 2\n",
    "        epsilon = 0.1\n",
    "        x1 = np.random.uniform(mean1, scale1, n)\n",
    "        x2 = np.random.uniform(mean2, scale2, n)\n",
    "        X = np.concatenate([x1, x2]).reshape(-1, 1)\n",
    "        y = np.concatenate([np.ones(len(x1)), -np.ones(len(x2))])\n",
    "\n",
    "        return tunning_k_plots(X, y, epsilon, n, C_0, mean1, scale1, mean2, scale2)\n",
    "    \n",
    "\n",
    "    search_space = {\n",
    "        'nvalues': np.arange (50, 2000, 50),\n",
    "        'C_0 values': np.arange (0.05, 2, 0.01)\n",
    "    }\n",
    "    \n",
    "    #direction = \"maximize\"\n",
    "    study = optuna.create_study(sampler=optuna.samplers.GridSampler(search_space))\n",
    "    study.optimize(objective, n_trials =500)\n",
    "    return study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162a3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = make_contour_plot()\n",
    "# optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342fad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b714bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
