{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48224979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import sklearn\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from PyNomaly import loop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoOP():\n",
    "\n",
    "    def fit_predict(X, y, epsilon, k=None, Plotting=None):\n",
    "        if k==None: #Estimate for K according to PyNormaly\n",
    "            k=round(np.sqrt(len(X)))\n",
    "    \n",
    "        scaler = MinMaxScaler(feature_range=(0, 1)) #Scaller between 0 and 1\n",
    "        X_scalled = scaler.fit_transform(X)\n",
    "        \n",
    "        final_points = []\n",
    "        y_labels = np.sort(np.unique(y, return_counts=True)[0])\n",
    "        dict_labels = {}\n",
    "        \n",
    "        for label in y_labels: \n",
    "            indexes = np.where(y==label)[0]\n",
    "            data = X[list(indexes)[:]]\n",
    "            q3, q1 = np.percentile(data, [75 ,25])\n",
    "            iqr = q3 - q1\n",
    "            bins = 2*iqr/(len(data)**(1/3))\n",
    "            bins_array = np.arange(min(data), max(data)+bins, step=bins)\n",
    "            full_density = np.histogram(data, bins=bins_array, density=True)[0]\n",
    "            max_density = max(full_density)\n",
    "            min_density = min(full_density)\n",
    "            dict_labels[label] = [min_density, max_density]\n",
    "        \n",
    "        final_plot = []\n",
    "        dict_probabilities = {}\n",
    "                \n",
    "        for point in X_scalled:\n",
    "            sub_X = X_scalled\n",
    "            sub_y = y\n",
    "            \n",
    "            for y_label in y_labels:\n",
    "                sub_y = np.append(sub_y, y_label)\n",
    "                sub_X = np.append(sub_X, point)\n",
    "            \n",
    "            all_Above_Epsilon = True\n",
    "            probabilities = loop.LocalOutlierProbability(sub_X, extent=2, n_neighbors=k, cluster_labels=list(sub_y), progress_bar=False).fit().local_outlier_probabilities\n",
    "            \n",
    "            for index, label in enumerate(y_labels):\n",
    "                if not label in dict_probabilities:\n",
    "                    dict_probabilities[label] = [1-probabilities[-(index+1)]]\n",
    "                else:\n",
    "                    dict_probabilities[label].extend([1-probabilities[-(index+1)]])\n",
    "\n",
    "                \n",
    "        for key in dict_probabilities.keys():\n",
    "            min_val, max_val = dict_labels[key][0], dict_labels[key][1]\n",
    "            scaler_values = MinMaxScaler(feature_range=(min_val, max_val)) #Scaller between the min and max of bin size.\n",
    "            dict_probabilities[key] = scaler_values.fit_transform(np.asarray(dict_probabilities[key]).reshape(-1, 1)).flatten()\n",
    "\n",
    "        final_score = np.min(list(dict_probabilities.values()), axis=0)\n",
    "        indexes = np.where(final_score >= epsilon)[0]\n",
    "        \n",
    "        if Plotting:\n",
    "            plt.scatter(scaler.inverse_transform(X_scalled), final_score) \n",
    "            plt.scatter(Plotting[0], Plotting[1], alpha=0.4, c=\"red\")\n",
    "            plt.xlabel('Coordinates') \n",
    "            plt.ylabel('1-Percentage')\n",
    "            plt.title(\"LoOP percentages per point\")\n",
    "            plt.legend([\"Estimated Density\", \"True Density\"], fontsize=8)\n",
    "            plt.show()\n",
    "\n",
    "        overlap_loop = X_scalled[list(indexes)[:]]\n",
    "        if len(overlap_loop) != 0:\n",
    "            overlap_loop = scaler.inverse_transform(overlap_loop)\n",
    "        return overlap_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9098e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_loop_estimate():\n",
    "    np.random.seed(0)\n",
    "    epsilon = 0\n",
    "    size = 200\n",
    "    mean1 = 0  \n",
    "    mean2 = 2 \n",
    "    scale1 = 1\n",
    "    scale2 = 1\n",
    "\n",
    "    x1 = np.random.normal(mean1, scale1, size)\n",
    "    x2 = np.random.normal(mean2, scale2, size)\n",
    "    X = np.concatenate([x1, x2]).reshape(-1, 1)\n",
    "    y = np.concatenate([np.ones(len(x1)), -np.ones(len(x2))])\n",
    "\n",
    "    \n",
    "    # Get true distribution and overlap\n",
    "    f1_distribution = stats.norm.pdf(x=x1, loc=mean1, scale=scale1)\n",
    "    f2_distribution = stats.norm.pdf(x=x2, loc=mean2, scale=scale2)\n",
    "    # Plot the distribution of two classes, overlap region and overlap points\n",
    "    plt.scatter(x1, f1_distribution, alpha=0.3)\n",
    "    plt.scatter(x2, f2_distribution, alpha=0.3)\n",
    "\n",
    "    f1_distribution = stats.norm.pdf(x=X, loc=mean1, scale=scale1)\n",
    "    f2_distribution = stats.norm.pdf(x=X, loc=mean2, scale=scale2)\n",
    "    class_ov = (f1_distribution > epsilon) & (f2_distribution > epsilon)\n",
    "    X_coor = X[class_ov]\n",
    "    plt.scatter(X_coor, np.minimum(f1_distribution[class_ov], f2_distribution[class_ov]), alpha=1, c=\"red\")\n",
    "    plt.legend([\"x1\", \"x2\", \"overlapping points\"], fontsize=8)\n",
    "\n",
    "    plt.xlabel(\"Coordinates\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Overlapping points of two normaly distributed function\")\n",
    "    plt.show()\n",
    "    \n",
    "    f1_distribution = stats.norm.pdf(x=X, loc=mean1, scale=scale1)\n",
    "    f2_distribution = stats.norm.pdf(x=X, loc=mean2, scale=scale2)\n",
    "    class_ov = (f1_distribution > epsilon) & (f2_distribution > epsilon)\n",
    "    X_coor = X[class_ov]\n",
    "\n",
    "\n",
    "    LoOP.fit_predict(X, y, epsilon, k=None, Plotting=[X_coor, np.minimum(f1_distribution[class_ov], f2_distribution[class_ov])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
